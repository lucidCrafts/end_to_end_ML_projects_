[ 2023-09-22 19:51:30,363 ] 41 root - INFO -Data Ingestion method is runnning..
[ 2023-09-22 19:51:31,721 ] 54 root - INFO -The local dataset is loaded to a variable
[ 2023-09-22 19:51:31,721 ] 57 root - INFO -The dataset is being balanced..
[ 2023-09-22 19:51:41,287 ] 60 root - INFO -The train test split is starting
[ 2023-09-22 19:51:41,412 ] 65 root - INFO -            Time        V1        V2        V3        V4        V5        V6        V7        V8        V9       V10       V11  ...       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28  Amount  Class
9341     13558.0  1.148607 -0.004154 -0.231106  1.124256  0.696077  1.177523 -0.160142  0.201478  1.568269 -0.320290  0.407096  ...  0.360271 -0.122816 -0.294334 -0.550620 -0.309693 -1.773489  0.791006 -0.263954 -0.008489 -0.011284   58.80      0
210529  138022.0 -0.910538 -0.971254  1.033829 -1.514111 -1.068542  0.148626 -0.660712  0.694582 -0.563151 -0.396853 -0.058963  ...  1.073261  0.362532  0.183422  0.082033  0.245169 -0.347895 -0.046626 -0.366928 -0.130325 -0.161839  142.30      0
51525    44997.0  1.222501  0.491904 -0.082522  0.987913  0.164676 -0.845453  0.515114 -0.258261 -0.667442  0.186485  1.479639  ...  0.029591 -0.076698  0.068123  0.244725 -0.173798  0.373883  0.849200 -0.317268 -0.007417  0.003691    7.99      0
128333   78673.0  1.184303 -0.066290  0.400333 -0.048278 -0.447460 -0.521259 -0.103204 -0.044640 -0.032670 -0.048690  1.276254  ...  0.486907  0.041195 -0.268415 -0.900138  0.112504  0.032476  0.046804  0.472132 -0.068010  0.008341   40.00      0
252025  155618.0 -0.484059  0.439377 -2.033102 -3.398765  2.209264  3.175789 -0.566306  0.423994 -1.281704  0.137172 -0.370828  ... -0.509811 -0.171988  1.344784  1.271853  0.055813  0.735276 -0.629507 -0.178298  0.394319  0.240147   15.00      0
168273  119146.0  2.303017 -1.394210 -1.461872 -1.927293 -0.475566  0.338937 -1.110049 -0.023149 -1.544721  1.709313 -0.074360  ...  0.476741 -0.304018 -0.167936 -0.015918  0.110499 -0.355835 -0.038535 -0.149190  0.003649 -0.061394   30.00      0
25045    33495.0  0.938982 -1.394941  0.762418 -0.367622 -1.940557 -0.979570 -0.705967 -0.067070 -0.275167  0.547471 -0.282614  ...  0.229457  0.391976  0.253837  0.065936 -0.084465  0.674680  0.080818 -0.334766 -0.022275  0.064064  227.04      0
148297   89686.0  1.947333 -0.214696 -0.661535  1.669166 -0.333621 -0.415828 -0.135561 -0.012630  1.342184  0.031616 -1.663031  ...  0.234677 -0.413309 -0.349979 -0.668010  0.259902 -0.086449 -0.006093 -0.811074  0.032931 -0.047223    6.00      0
179325  124026.0  0.117760  0.815139 -0.148106 -0.826108  0.884290 -0.539896  0.965332 -0.121557  0.078447 -0.398965 -1.914225  ...  0.310264 -0.027739 -0.333033 -0.790544 -0.055813 -1.019808 -0.362195  0.203901  0.243752  0.086118    2.69      0
142117   84582.0  1.082979 -0.753885  0.154108 -0.486242 -0.973420 -1.095174 -0.018315 -0.270580 -1.148998  0.520979  0.580169  ...  0.192279  0.303059 -0.056484 -0.576194  0.101351  0.585301  0.156616 -0.547925 -0.024265  0.040481  150.00      0
248569  154000.0  0.010337  1.114262 -0.015103 -0.519108  1.069169 -1.209449  1.359823 -0.597543 -0.134204 -0.904306 -0.262601  ... -0.604762 -0.025253  0.241265  0.982088 -0.409093 -0.118391  0.130626 -0.180082 -0.218388 -0.157437    1.45      0
210364  137946.0  1.982726 -1.422500 -0.368154 -1.044395 -1.104712  0.467811 -1.440085  0.251945  0.198085  0.825464  0.361131  ...  0.844157  0.185192  0.286834  0.636742  0.164333  0.201085 -0.427469 -0.282773  0.012637 -0.029910   90.00      0
84337    60261.0 -0.467941  1.027030  1.680192 -0.103337 -0.081868 -0.686064  0.621184  0.051129 -0.713540 -0.150747  1.532845  ...  0.224764  0.117288 -0.160277 -0.420127 -0.016229  0.524698 -0.241950  0.040159  0.264211  0.113429    1.29      0
233922  147755.0 -0.583084  1.521545  1.580662  4.366846 -0.085480  2.065880 -1.382605 -2.097266 -1.820959  1.084252  0.091315  ...  1.099998  0.747413 -0.891772  1.531633  0.086832  0.739802 -0.856207  0.416680  0.224198  0.230560   21.18      0
236183  148701.0 -2.294590 -2.566528 -1.842355 -4.294888  1.672855 -0.196827  0.206896  0.707631 -0.066897 -1.540219  0.389725  ... -1.634618  0.294464  0.267961  0.343342  0.406721 -0.984052 -0.179999 -0.955373  0.336323 -0.097173  238.47      0
164421  116702.0 -2.107488 -2.564857  0.739297 -1.683669 -0.542289  2.900845  0.030964  0.327518  3.334038 -1.140567  0.352138  ...  0.908386 -1.428645 -0.092630  2.018515  1.163707 -0.608218 -1.177369 -0.106490  0.279801  0.010782  278.24      0
244257  152272.0 -0.311031  0.866357  0.281061 -0.562421  0.275203 -1.957418  1.313502 -0.328496 -0.128157 -1.417128  0.086256  ... -1.495501 -0.171122  0.323996  0.854397 -0.178333  0.833020  0.277496 -0.262983  0.004816  0.053001   47.00      0
206728  136339.0 -0.172236  1.037064 -0.152709 -0.160857  1.249334 -0.010867  0.783692 -0.002969 -0.675067 -0.555646  0.812716  ...  1.398742  0.079089 -0.191391 -0.549541 -0.010853  0.146133 -0.768217  0.260807  0.005084  0.215565    0.99      0
67444    52536.0 -1.198728  0.450311  1.838651 -1.085418 -0.867175 -0.002543 -0.388867  0.886245  0.623171 -1.021073 -0.112408  ...  0.197649 -0.129812 -0.140718 -0.423241 -0.085697  0.000702 -0.113541  0.809878  0.119718  0.059406   20.39      0
99905    67329.0 -0.328625  1.036104  1.099032  0.663111  0.215034 -0.314231  0.596120  0.122310 -0.573569  0.190124  0.660365  ...  0.824061  0.065926  0.122117  0.431615 -0.205829 -0.024074 -0.226196 -0.309652  0.405422  0.209116    3.75      0

[20 rows x 31 columns]
[ 2023-09-22 19:51:59,738 ] 87 root - INFO -The data ingested, and is ready to save to the artifacts directory
[ 2023-09-22 19:52:02,083 ] 42 root - INFO -Numerical columns: ['Time', 'Amount']
[ 2023-09-22 19:52:02,083 ] 67 root - INFO -Read train and test data completed
[ 2023-09-22 19:52:02,083 ] 69 root - INFO -Obtaining preprocessing object
[ 2023-09-22 19:52:02,116 ] 84 root - INFO -Applying preprocessing object on training dataframe and testing dataframe.
[ 2023-09-22 19:52:02,162 ] 99 root - INFO -Saved preprocessing object.
[ 2023-09-22 19:52:02,175 ] 56 root - INFO -Split training and test input data
[ 2023-09-22 19:52:02,175 ] 66 root - INFO -None
[ 2023-09-22 19:52:02,176 ] 54 root - INFO -Evaluating model: Decision Tree :{'criterion': ['gini', 'entropy'], 'max_depth': [None, 5, 10, 20]}: 
[ 2023-09-22 19:52:26,796 ] 81 root - INFO -Decision Tree F1 score is 0.014977533699450821
[ 2023-09-22 19:52:26,796 ] 54 root - INFO -Evaluating model: Gradient Boosting :{'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}: 
[ 2023-09-22 20:13:10,388 ] 81 root - INFO -Gradient Boosting F1 score is 0.010302351623740201
[ 2023-09-22 20:13:10,388 ] 54 root - INFO -Evaluating model: K-Neighbors :{'n_neighbors': [3, 5, 10], 'weights': ['uniform', 'distance']}: 
[ 2023-09-22 20:13:47,217 ] 81 root - INFO -K-Neighbors F1 score is 0.010027347310847767
[ 2023-09-22 20:13:47,218 ] 54 root - INFO -Evaluating model: XGBoost :{'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}: 
[ 2023-09-22 20:19:08,798 ] 81 root - INFO -XGBoost F1 score is 0.008544400366188589
[ 2023-09-22 20:19:08,798 ] 54 root - INFO -Evaluating model: AdaBoost :{'n_estimators': [50, 100, 200], 'learning_rate': [0.01, 0.1, 0.2]}: 
[ 2023-09-22 20:28:37,167 ] 81 root - INFO -AdaBoost F1 score is 0.008300616937745375
[ 2023-09-22 20:28:37,167 ] 54 root - INFO -Evaluating model: Logistic Regression :{'C': [0.1, 1.0, 10.0], 'penalty': ['l1', 'l2', 'elasticnet', 'none'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}: 
[ 2023-09-22 20:29:24,965 ] 81 root - INFO -Logistic Regression F1 score is 0.00368350216051569
[ 2023-09-22 20:29:24,965 ] 54 root - INFO -Evaluating model: Neural Net :{'epochs': [5], 'batch_size': [10, 20], 'optimizer': ['Adam'], 'neurons': [3], 'activation': ['relu'], 'input_shape': [(2,)]}: 
[ 2023-09-22 20:53:27,187 ] 81 root - INFO -Neural Net F1 score is 0.0045708481462671405
[ 2023-09-22 20:53:27,188 ] 130 root - INFO -Model training is done..
